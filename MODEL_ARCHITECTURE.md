# Kiáº¿n TrÃºc MÃ´ HÃ¬nh AI Vietnamese Keyboard

## ğŸ¯ Tá»•ng Quan Há»‡ Thá»‘ng

Vietnamese AI Keyboard lÃ  má»™t há»‡ thá»‘ng thÃ´ng minh sá»­ dá»¥ng mÃ´ hÃ¬nh GPT tÃ¹y chá»‰nh Ä‘á»ƒ dá»± Ä‘oÃ¡n vÃ  gá»£i Ã½ tá»« tiáº¿ng Viá»‡t tá»« input khÃ´ng dáº¥u. Há»‡ thá»‘ng káº¿t há»£p hai phÆ°Æ¡ng phÃ¡p chÃ­nh:

1. **Frequency-based prediction** (Dá»± Ä‘oÃ¡n dá»±a trÃªn táº§n suáº¥t)
2. **Context-aware neural prediction** (Dá»± Ä‘oÃ¡n neural nháº­n biáº¿t ngá»¯ cáº£nh)

## ğŸ—ï¸ Kiáº¿n TrÃºc Tá»•ng Thá»ƒ

```
Input khÃ´ng dáº¥u â†’ Text Processor â†’ AI Recommender â†’ Output cÃ³ dáº¥u
                                        â†“
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚          AI Engine                  â”‚
                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                 â”‚  Tokenizer  â”‚  GPT Model  â”‚ Cache   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š CÃ¡c ThÃ nh Pháº§n ChÃ­nh

### 1. Vietnamese Non-Accented GPT Model

**Vá»‹ trÃ­**: `ml/models/gpt_model.py`

#### ğŸ§  Kiáº¿n TrÃºc MÃ´ HÃ¬nh

**Cáº¥u hÃ¬nh máº·c Ä‘á»‹nh:**

- **Vocab size**: 50,000 tokens
- **Block size**: 32 tokens (sequence length)
- **Layers**: 8 Transformer blocks
- **Attention heads**: 8 heads
- **Embedding dimension**: 256
- **Dropout**: 0.1

#### ğŸ”§ ThÃ nh Pháº§n Chi Tiáº¿t

##### Causal Self-Attention

```python
class CausalSelfAttention:
    - Multi-head attention vá»›i causal masking
    - Äáº£m báº£o mÃ´ hÃ¬nh chá»‰ nhÃ¬n tháº¥y tokens trÆ°á»›c Ä‘Ã³
    - Attention dropout Ä‘á»ƒ regularization
```

##### MLP Block

```python
class MLP:
    - Linear layer: n_embd â†’ 4*n_embd
    - GELU activation
    - Linear layer: 4*n_embd â†’ n_embd
    - Dropout
```

##### Transformer Block

```python
class Block:
    - LayerNorm â†’ Self-Attention â†’ Residual Connection
    - LayerNorm â†’ MLP â†’ Residual Connection
```

### 2. Tokenizer System

**Vá»‹ trÃ­**: `ml/tokenizer.py`

#### ğŸ”¤ Chá»©c NÄƒng ChÃ­nh

1. **Word-to-ID mapping**: Chuyá»ƒn Ä‘á»•i tá»« thÃ nh ID sá»‘
2. **Non-accented mapping**: Map tá»« cÃ³ dáº¥u â†’ khÃ´ng dáº¥u
3. **Frequency tracking**: Theo dÃµi táº§n suáº¥t xuáº¥t hiá»‡n cá»§a tá»«
4. **Special tokens**: `<pad>`, `<unk>`, `<sos>`, `<eos>`

#### ğŸ’¾ Dá»¯ Liá»‡u LÆ°u Trá»¯

- `vocab.json`: Tá»« Ä‘iá»ƒn word â†’ ID
- `word_to_non_accented.json`: Map tá»« cÃ³ dáº¥u â†’ khÃ´ng dáº¥u
- `non_accented_to_words.json`: Map khÃ´ng dáº¥u â†’ list tá»« cÃ³ dáº¥u
- `word_freq.json`: Táº§n suáº¥t xuáº¥t hiá»‡n cá»§a tá»«

### 3. Inference Engine

**Vá»‹ trÃ­**: `ml/inference.py`

#### ğŸš€ Quy TrÃ¬nh Dá»± ÄoÃ¡n

##### BÆ°á»›c 1: Dá»± Ä‘oÃ¡n dá»±a trÃªn táº§n suáº¥t

```python
def _get_tokenizer_suggestions():
    - TÃ¬m cÃ¡c tá»« cÃ³ mapping vá»›i input khÃ´ng dáº¥u
    - Sáº¯p xáº¿p theo táº§n suáº¥t xuáº¥t hiá»‡n
    - Tráº£ vá» top candidates vá»›i confidence score
```

##### BÆ°á»›c 2: Dá»± Ä‘oÃ¡n dá»±a trÃªn ngá»¯ cáº£nh (Neural)

```python
def _get_model_suggestions():
    - Encode ngá»¯ cáº£nh (5 tá»« gáº§n nháº¥t)
    - Forward pass qua GPT model
    - Láº¥y top-k predictions
    - Filter theo non-accented input
    - Tráº£ vá» candidates vá»›i probability scores
```

##### BÆ°á»›c 3: Káº¿t há»£p vÃ  xáº¿p háº¡ng

```python
def _combine_suggestions():
    - Tokenizer suggestions: weight = 0.7
    - Model suggestions: weight = 0.8
    - Combined suggestions: model*0.8 + tokenizer*0.2
    - Sort theo confidence score giáº£m dáº§n
```

### 4. AI Recommender

**Vá»‹ trÃ­**: `core/ai_recommender.py`

#### ğŸ›ï¸ Chá»©c NÄƒng ChÃ­nh

1. **Context management**: Quáº£n lÃ½ ngá»¯ cáº£nh 5 tá»« gáº§n nháº¥t
2. **Performance tracking**: Theo dÃµi hiá»‡u suáº¥t dá»± Ä‘oÃ¡n
3. **Fallback handling**: Xá»­ lÃ½ khi mÃ´ hÃ¬nh khÃ´ng kháº£ dá»¥ng
4. **Cache optimization**: Tá»‘i Æ°u hÃ³a báº±ng cache

## âš™ï¸ Quy TrÃ¬nh Training

### 1. Data Preprocessing

**Vá»‹ trÃ­**: `ml/data_preprocessor.py`

```python
Corpus text â†’ Tokenization â†’ Word mapping â†’ Vocabulary building
                 â†“
Training pairs generation (input_sequence â†’ target_word)
                 â†“
Save: vocab.json, word_mappings.json, training_pairs.csv
```

### 2. Model Training

**Vá»‹ trÃ­**: `train_model.py`

```python
Load training pairs â†’ Create DataLoader â†’ Initialize GPT model
                 â†“
Training loop: Forward pass â†’ Loss calculation â†’ Backprop
                 â†“
Validation â†’ Save best checkpoint
```

## ğŸ§© Thuáº­t ToÃ¡n Dá»± ÄoÃ¡n Chi Tiáº¿t

### Input Processing

1. **Text cleaning**: Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, chuáº©n hÃ³a
2. **Non-accented conversion**: Chuyá»ƒn input thÃ nh dáº¡ng khÃ´ng dáº¥u
3. **Context extraction**: Láº¥y 5 tá»« gáº§n nháº¥t lÃ m ngá»¯ cáº£nh

### Prediction Pipeline

#### PhÆ°Æ¡ng phÃ¡p 1: Frequency-based

```
Input: "xinchao"
â†“
Lookup trong non_accented_to_words mapping
â†“
Káº¿t quáº£: [("xin chÃ o", 0.85), ("xin chao", 0.10), ...]
```

#### PhÆ°Æ¡ng phÃ¡p 2: Context-aware Neural

```
Context: ["tÃ´i", "muá»‘n", "nÃ³i"]
Input: "xinchao"
â†“
Encode context: [245, 1023, 567] â†’ Tensor(1, 3)
â†“
GPT forward: context_tensor â†’ logits(1, vocab_size)
â†“
Top-k sampling: â†’ [("xin chÃ o", 0.92), ("xin chao", 0.05), ...]
â†“
Filter by non-accented match vá»›i "xinchao"
```

### Combining Strategy

```python
final_score = {
    "frequency_only": freq_score * 0.7,
    "model_only": model_score * 1.0,
    "combined": model_score * 0.8 + freq_score * 0.2
}
```

## ğŸ“Š Tá»‘i Æ¯u HÃ³a Hiá»‡u Suáº¥t

### 1. Caching System

- **Key**: `f"{input}_{context}_{max_suggestions}_{use_model}_{temperature}"`
- **Hit rate tracking**: Theo dÃµi tá»· lá»‡ cache hit
- **Memory management**: Giá»›i háº¡n kÃ­ch thÆ°á»›c cache

### 2. Model Optimization

- **Inference mode**: `model.eval()` vÃ  `torch.no_grad()`
- **Device optimization**: Auto-detect CUDA/CPU
- **Batch processing**: Xá»­ lÃ½ context theo batch

### 3. Tokenizer Optimization

- **Pre-loaded mappings**: Load táº¥t cáº£ mappings vÃ o memory
- **Fast lookup**: Sá»­ dá»¥ng dictionary cho O(1) lookup
- **Frequency sorting**: Pre-sort theo frequency

## ğŸ¯ Äiá»ƒm Máº¡nh Cá»§a Kiáº¿n TrÃºc

### 1. Hybrid Approach

- **Reliability**: Fallback vá» frequency-based khi model fail
- **Accuracy**: Neural model cung cáº¥p context-aware predictions
- **Speed**: Cache system giáº£m latency

### 2. Scalability

- **Modular design**: CÃ¡c component Ä‘á»™c láº­p, dá»… thay tháº¿
- **Configurable**: Dá»… dÃ ng Ä‘iá»u chá»‰nh parameters
- **Extensible**: CÃ³ thá»ƒ thÃªm more prediction methods

### 3. Vietnamese-specific Optimization

- **Non-accented mapping**: Tá»‘i Æ°u cho cÃ¡ch gÃµ tiáº¿ng Viá»‡t
- **Frequency weighting**: Æ¯u tiÃªn tá»« phá»• biáº¿n
- **Context awareness**: Hiá»ƒu ngá»¯ cáº£nh tiáº¿ng Viá»‡t

## ğŸ”„ Luá»“ng Xá»­ LÃ½ HoÃ n Chá»‰nh

```
User input: "toi muon an com"
                â†“
Text processing: clean + normalize
                â†“
Word segmentation: ["toi", "muon", "an", "com"]
                â†“
For each word:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Frequency predictions               â”‚
    â”‚ + Context neural predictions       â”‚
    â”‚ â†’ Combine & rank                   â”‚
    â”‚ â†’ Cache result                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
Final suggestions: ["tÃ´i muá»‘n Äƒn cÆ¡m", "tÃ´i muá»‘n Äƒn com", ...]
                â†“
UI display vá»›i confidence scores
```

## ğŸ“ˆ Metrics & Monitoring

### Performance Metrics

- **Prediction accuracy**: % correct predictions trong top-k
- **Response latency**: Thá»i gian tá»« input â†’ output
- **Cache hit rate**: Tá»· lá»‡ cache hits
- **Model coverage**: % cases sá»­ dá»¥ng neural model

### Quality Metrics

- **Relevance score**: Má»©c Ä‘á»™ phÃ¹ há»£p vá»›i ngá»¯ cáº£nh
- **Diversity score**: Äa dáº¡ng trong suggestions
- **User satisfaction**: Tracking user selections

---

_File nÃ y mÃ´ táº£ kiáº¿n trÃºc vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng chi tiáº¿t cá»§a Vietnamese AI Keyboard. Äá»ƒ hiá»ƒu sÃ¢u hÆ¡n, hÃ£y tham kháº£o source code trong cÃ¡c thÆ° má»¥c tÆ°Æ¡ng á»©ng._
